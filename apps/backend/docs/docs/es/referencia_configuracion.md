# Referencia de Configuraci贸n

Voice2Machine utiliza un sistema de configuraci贸n jer谩rquico y tipado basado en **Pydantic V2**. Esto garantiza que cualquier valor incorrecto en la configuraci贸n (ej. un tipo de dato err贸neo) detenga el inicio del servicio con un mensaje claro.

## 锔 Archivo `config.toml`

La fuente principal de configuraci贸n es el archivo `config.toml` ubicado en la ra铆z del proyecto. Este archivo debe seguir la estructura definida a continuaci贸n.

!!! tip "Recarga en Caliente"
    La mayor铆a de las configuraciones pueden actualizarse en tiempo real mediante el comando IPC `UPDATE_CONFIG` o editando el archivo `config.toml` (requiere reinicio en algunos casos como cambio de modelo VRAM).

---

##  Variables de Entorno

Cualquier configuraci贸n puede ser sobreescrita mediante variables de entorno. El formato es:

`V2M_[SECCION]__[CAMPO]` (Doble guion bajo como separador).

Ejemplo:
*   `config.toml`: `[gemini] api_key = "..."`
*   Env Var: `V2M_GEMINI__API_KEY="AIzaSy..."`

---

##  Secciones de Configuraci贸n

### 1. `[paths]`
Rutas del sistema y archivos temporales.

| Campo | Tipo | Defecto | Descripci贸n |
| :--- | :--- | :--- | :--- |
| `recording_flag` | Path | `$RUNTIME/v2m_recording.pid` | Archivo bandera que indica grabaci贸n activa. |
| `audio_file` | Path | `$RUNTIME/v2m_audio.wav` | Archivo temporal donde se guarda el audio grabado. |
| `log_file` | Path | `$RUNTIME/v2m_debug.log` | Archivo de logs para depuraci贸n. |

### 2. `[transcription]`
Configuraci贸n del motor de transcripci贸n principal.

#### `[transcription.whisper]`
Par谩metros para el motor Faster-Whisper.

| Campo | Tipo | Defecto | Descripci贸n |
| :--- | :--- | :--- | :--- |
| `model` | str | `"large-v2"` | Modelo Whisper (`tiny`, `base`, `small`, `medium`, `large-v2`, `large-v3`). |
| `language` | str | `"es"` | C贸digo ISO del idioma (o `"auto"`). |
| `device` | str | `"cuda"` | Dispositivo de c贸mputo (`cuda` o `cpu`). |
| `compute_type` | str | `"int8_float16"` | Precisi贸n (`float16`, `int8`). Afecta uso de VRAM. |
| `vad_filter` | bool | `true` | Si activar el filtro de voz (VAD) interno de Whisper. |
| `keep_warm` | bool | `true` | Mantener el modelo en VRAM tras la transcripci贸n. |

#### `[transcription.whisper.vad_parameters]`
Ajuste fino del detector de voz.

| Campo | Tipo | Defecto | Descripci贸n |
| :--- | :--- | :--- | :--- |
| `threshold` | float | `0.3` | Sensibilidad (0.0 a 1.0). Mayor = menos sensible al ruido. |
| `min_speech_duration_ms` | int | `250` | M铆nima duraci贸n para considerar habla. |

### 3. `[llm]`
Configuraci贸n general de Modelos de Lenguaje.

| Campo | Tipo | Defecto | Descripci贸n |
| :--- | :--- | :--- | :--- |
| `backend` | enum | `"local"` | Motor a usar: `"local"`, `"gemini"`, o `"ollama"`. |

#### `[llm.local]` (Llama.cpp)
| Campo | Tipo | Defecto | Descripci贸n |
| :--- | :--- | :--- | :--- |
| `model_path` | Path | `models/...gguf` | Ruta relativa al archivo GGUF del modelo. |
| `n_gpu_layers` | int | `-1` | Capas a descargar a GPU (-1 = todas). |
| `n_ctx` | int | `2048` | Ventana de contexto. |

#### `[llm.ollama]`
| Campo | Tipo | Defecto | Descripci贸n |
| :--- | :--- | :--- | :--- |
| `host` | str | `"http://localhost:11434"` | URL del servidor Ollama. |
| `model` | str | `"gemma2:2b"` | Nombre del modelo a solicitar. |
| `keep_alive` | str | `"5m"` | Tiempo para mantener el modelo cargado. |

### 4. `[gemini]` (Google AI)
Requiere API Key v谩lida.

| Campo | Tipo | Defecto | Descripci贸n |
| :--- | :--- | :--- | :--- |
| `api_key` | str | `null` | Clave de API de Google AI Studio. |
| `model` | str | `"gemini-1.5-flash..."` | Identificador del modelo. |
| `temperature` | float | `0.3` | Creatividad de la respuesta. |

### 5. `[notifications]`
Comportamiento de las notificaciones de escritorio.

| Campo | Tipo | Defecto | Descripci贸n |
| :--- | :--- | :--- | :--- |
| `expire_time_ms` | int | `3000` | Tiempo en pantalla (ms). |
| `auto_dismiss` | bool | `true` | Cerrar autom谩ticamente. |

---

##  Ejemplo Completo (`config.toml`)

```toml
[transcription.whisper]
model = "large-v3-turbo"
language = "es"
compute_type = "float16"

[transcription.whisper.vad_parameters]
threshold = 0.4

[llm]
backend = "ollama"

[llm.ollama]
model = "llama3.2"
keep_alive = "10m"

[notifications]
expire_time_ms = 5000
```
