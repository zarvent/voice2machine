# BACKEND

el corazÃ³n de voice2machine. aquÃ­ vive toda la lÃ³gica que convierte tu voz en texto y lo refina con inteligencia artificial.

---

## estructura

```
backend/
â”œâ”€â”€ models/      # modelos de machine learning
â”œâ”€â”€ logs/        # registro de actividad
â”œâ”€â”€ prompts/     # plantillas para LLMs
â””â”€â”€ src/         # cÃ³digo fuente de la aplicaciÃ³n
```

---

## ğŸ“¦ models

**Â¿quÃ© es?**  
espacio reservado para los modelos de machine learning que usa la aplicaciÃ³n localmente.

**Â¿para quÃ© sirve?**  
almacena archivos pesados de modelos de lenguaje (formato GGUF) que no pueden versionarse en git por su tamaÃ±o. estos modelos permiten procesar texto sin depender de servicios cloud.

**ejemplos de contenido:**
- `qwen2.5-3b-instruct-q4_k_m.gguf` â†’ modelo local para refinamiento de texto
- cualquier modelo compatible con llama.cpp

**nota importante:** estos archivos estÃ¡n excluidos en `.gitignore` por su peso. debes descargarlos manualmente segÃºn las instrucciones de instalaciÃ³n.

---

## ğŸ“‹ logs

**Â¿quÃ© es?**  
directorio donde se guardan los registros de actividad de la aplicaciÃ³n.

**Â¿para quÃ© sirve?**  
permite diagnosticar problemas, auditar el uso del sistema y entender el comportamiento de los componentes en ejecuciÃ³n.

**archivos que encontrarÃ¡s:**
- `llm.log` â†’ interacciones con modelos de lenguaje (API calls, tokens procesados, tiempos de respuesta)
- `process.log` â†’ eventos generales del daemon (inicio, detenciÃ³n, comandos recibidos)

**nota importante:** estos archivos `.log` tambiÃ©n estÃ¡n excluidos en `.gitignore` y se generan automÃ¡ticamente durante el uso.

---

## ğŸ’¬ prompts

**Â¿quÃ© es?**  
colecciÃ³n de plantillas de texto que guÃ­an el comportamiento de los modelos de lenguaje.

**Â¿para quÃ© sirve?**  
separar la ingenierÃ­a de prompts del cÃ³digo permite iterar y mejorar las instrucciones sin tocar la lÃ³gica de la aplicaciÃ³n. cualquier persona puede editar un prompt sin ser programador.

**contenido destacado:**
- `refine_system.txt` â†’ prompt principal para refinar transcripciones de voz
- `README.md` â†’ documentaciÃ³n completa sobre cÃ³mo crear y usar prompts

**filosofÃ­a:** los prompts son cÃ³digo que habla con mÃ¡quinas inteligentes. merecen su propio espacio y versionado.

---

## ğŸ’» src

**Â¿quÃ© es?**  
el cÃ³digo fuente completo de voice2machine. implementado como un paquete python moderno.

**Â¿para quÃ© sirve?**  
contiene toda la lÃ³gica de:
- transcripciÃ³n de audio con whisper
- refinamiento de texto con LLMs (local o cloud)
- gestiÃ³n del daemon persistente
- comunicaciÃ³n IPC entre procesos
- integraciÃ³n con el sistema operativo (notificaciones, portapapeles, audio)

**arquitectura:**  
sigue principios de **arquitectura hexagonal** (ports and adapters) para mantener el cÃ³digo desacoplado, testeable y mantenible.

```
src/v2m/
â”œâ”€â”€ application/     # casos de uso y servicios (transcripciÃ³n, LLM)
â”œâ”€â”€ core/            # nÃºcleo del sistema (CQRS, DI, interfaces)
â”œâ”€â”€ domain/          # entidades de negocio y errores
â””â”€â”€ infrastructure/  # adaptadores concretos (audio, notificaciones, sistema)
```

**punto de entrada:**  
`main.py` â†’ CLI unificado que puede actuar como daemon o cliente

**documentaciÃ³n completa:** consulta `src/v2m/README.md` para detalles de arquitectura interna.

---

## flujo de trabajo tÃ­pico

1. **daemon** carga modelo whisper en memoria â†’ esperando en `/tmp/v2m.sock`
2. **usuario** presiona atajo de teclado â†’ script envÃ­a comando al daemon
3. **daemon** graba audio â†’ transcribe con whisper â†’ copia a portapapeles
4. **usuario** (opcional) activa refinamiento â†’ llm procesa texto â†’ reemplaza portapapeles

todo sucede localmente, sin tocar internet (excepto si usas backend cloud para LLM).

---

## requisitos

- python 3.12+
- GPU con CUDA (para whisper acelerado)
- dependencias en `requirements.txt`

consulta `/docs/instalacion.md` para el setup completo.

---

## licencia

GNU General Public License v3.0 - ver [LICENSE](../../LICENSE)
