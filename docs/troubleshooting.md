#  Resoluci贸n de Problemas (Troubleshooting)

Esta gu铆a recopila los problemas m谩s comunes y sus soluciones. Si encuentras un error que no est谩 aqu铆, por favor revisa los logs en `/tmp/v2m.log`.

---

##  Problemas de Audio

### "No se detecta el micr贸fono" o Grabaci贸n vac铆a
*   **S铆ntoma**: El sistema dice "Grabaci贸n iniciada" pero al detenerse no transcribe nada o da error.
*   **Soluci贸n**:
    1.  Verifica que `ffmpeg` y `pactl` est茅n instalados.
    2.  Aseg煤rate de que tu micr贸fono predeterminado en el sistema operativo est茅 activo y con volumen.
    3.  Ejecuta `arecord -l` para listar dispositivos.

### La transcripci贸n corta frases o palabras
*   **Causa**: El VAD (Voice Activity Detection) puede ser demasiado agresivo.
*   **Soluci贸n**:
    1.  Edita `config.toml`.
    2.  En `[whisper.vad_parameters]`, reduce `threshold` (ej. a `0.3`) o aumenta `min_speech_duration_ms`.

---

##  Problemas de Rendimiento

### La transcripci贸n es muy lenta (>5 segundos para frases cortas)
*   **Causa**: Probablemente Whisper se est谩 ejecutando en la **CPU** en lugar de la **GPU**.
*   **Diagn贸stico**: Ejecuta `python scripts/test_whisper_gpu.py`.
*   **Soluci贸n**:
    1.  Verifica que tienes drivers NVIDIA y CUDA instalados.
    2.  Reinstala `torch` con soporte CUDA expl铆cito.
    3.  En `config.toml`, asegura `device = "cuda"`.

### `OutOfMemoryError` (OOM) en GPU
*   **Causa**: El modelo `large-v3` es demasiado grande para tu VRAM.
*   **Soluci贸n**:
    1.  Cambia el modelo en `config.toml` a `medium` o `small`.
    2.  Cambia `compute_type` a `int8_float16` (h铆brido) si tu tarjeta lo soporta.

---

##  Problemas con Gemini (LLM)

### "Error de autenticaci贸n" o "API Key inv谩lida"
*   **Soluci贸n**:
    1.  Verifica que el archivo `.env` existe en la ra铆z.
    2.  Aseg煤rate de que la variable se llame `GEMINI_API_KEY`.
    3.  Genera una nueva clave en Google AI Studio.

### El texto refinado es peor que el original
*   **Soluci贸n**:
    1.  Ajusta el `system_prompt` en `src/v2m/infrastructure/gemini_llm_service.py` (o en `prompts/` si est谩 externalizado).
    2.  Baja la `temperature` en `config.toml` a `0.1` para hacerlo m谩s determinista.

---

##  Logs y Depuraci贸n

Para ver qu茅 est谩 pasando en tiempo real:

```bash
# Ver el log en vivo
tail -f /tmp/v2m.log
```

Si reportas un bug, por favor incluye las 煤ltimas l铆neas de este archivo.
