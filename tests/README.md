# üß™ Suite de Pruebas - v2m

Bienvenido al directorio de pruebas del proyecto voice2machine. Este documento
sirve como gu√≠a completa para entender, ejecutar y contribuir a las pruebas.

## Filosof√≠a de Testing

Las pruebas automatizadas son la primera l√≠nea de defensa contra regresiones.
Siguiendo el principio de "fail fast", nos permiten detectar problemas antes
de que lleguen a producci√≥n.

**Beneficios clave:**

- **Confianza para refactorizar**: Puedes cambiar c√≥digo sabiendo que las pruebas te avisar√°n si rompes algo.
- **Documentaci√≥n ejecutable**: Las pruebas demuestran c√≥mo se usa el c√≥digo.
- **Dise√±o mejorado**: C√≥digo dif√≠cil de probar suele ser c√≥digo mal dise√±ado.

## üìÅ Estructura del Directorio

```text
tests/
‚îú‚îÄ‚îÄ README.md                     # Esta gu√≠a
‚îú‚îÄ‚îÄ integration/                  # Pruebas de integraci√≥n (en desarrollo)
‚îî‚îÄ‚îÄ unit/                         # Pruebas unitarias
    ‚îú‚îÄ‚îÄ test_audio_recorder.py    # Componente de captura de audio
    ‚îú‚îÄ‚îÄ test_config.py            # Sistema de configuraci√≥n
    ‚îî‚îÄ‚îÄ test_vad_service.py       # Servicio de detecci√≥n de voz
```

### Tipos de pruebas

| Tipo | Prop√≥sito | Velocidad | Aislamiento |
|------|-----------|-----------|-------------|
| **Unitarias** | Verificar componentes individuales | R√°pidas (~ms) | Total (con mocks) |
| **Integraci√≥n** | Verificar interacci√≥n entre componentes | Medias (~s) | Parcial |
| **E2E** | Verificar flujos completos | Lentas (~min) | Ninguno |

En v2m priorizamos pruebas unitarias por su velocidad y determinismo.

## üöÄ Ejecuci√≥n de Pruebas

### Comandos b√°sicos

```bash
# Ejecutar todas las pruebas con output detallado
pytest tests/ -v

# Solo pruebas unitarias
pytest tests/unit/ -v

# Un archivo espec√≠fico
pytest tests/unit/test_vad_service.py -v

# Una prueba espec√≠fica (formato: archivo::funcion)
pytest tests/unit/test_vad_service.py::test_vad_process_with_speech -v
```

### An√°lisis de cobertura

La cobertura de c√≥digo mide qu√© porcentaje del c√≥digo fuente es ejecutado
por las pruebas. Una m√©trica √∫til, aunque no garantiza calidad por s√≠ sola.

```bash
# Generar reporte de cobertura en terminal
pytest tests/ --cov=src/v2m

# Generar reporte HTML interactivo
pytest tests/ --cov=src/v2m --cov-report=html
# Abrir htmlcov/index.html en navegador

# Fallar si la cobertura es menor al 80%
pytest tests/ --cov=src/v2m --cov-fail-under=80
```

## üìã Descripci√≥n de los M√≥dulos de Prueba

### test_audio_recorder.py

Verifica el componente `AudioRecorder`, responsable de la captura de audio
desde dispositivos de entrada del sistema.

| Prueba | Descripci√≥n | Tipo |
|--------|-------------|------|
| `test_stop_clears_frames` | Valida que stop() libere el buffer interno y falle en llamadas subsecuentes | Edge case |

**Conceptos clave:**

- Patr√≥n de acumulaci√≥n de frames
- Principio de single-use
- Test doubles con `unittest.mock`

### test_config.py

Verifica el sistema de configuraci√≥n basado en TOML.

| Prueba | Descripci√≥n | Tipo |
|--------|-------------|------|
| `test_config_loading` | Valida la carga correcta de par√°metros desde config.toml | Smoke test |

**Conceptos clave:**

- Configuraci√≥n externa (twelve-factor app)
- Contract testing

### test_vad_service.py

Verifica el servicio de Voice Activity Detection basado en Silero VAD.

| Prueba | Descripci√≥n | Tipo |
|--------|-------------|------|
| `test_vad_process_empty_audio` | Manejo robusto de entrada vac√≠a | Edge case |
| `test_vad_process_no_speech` | Correcta identificaci√≥n de silencio | Negative test |
| `test_vad_process_with_speech` | Extracci√≥n correcta de segmentos de voz | Happy path |
| `test_vad_uses_configured_threshold` | Prevenci√≥n de regresi√≥n (threshold hardcodeado) | Regression test |

**Conceptos clave:**

- Voice Activity Detection
- Teorema de Nyquist (sample rate 16kHz)
- Threshold/umbral de detecci√≥n

## üîß Configuraci√≥n del Entorno

### Dependencias

```bash
pip install pytest pytest-cov
```

### Fixtures de pytest

Las fixtures son el mecanismo de pytest para inyecci√≥n de dependencias en tests.
Reemplazan y mejoran el patr√≥n setUp/tearDown de unittest.

**Disponibles en test_vad_service.py:**

```python
@pytest.fixture
def vad_service() -> VADService:
    """Instancia base, sin modificaciones."""
    return VADService()

@pytest.fixture
def configured_vad_service() -> VADService:
    """Instancia con modelo mockeado para pruebas r√°pidas."""
    service = VADService()
    service.load_model = MagicMock()
    service.model = MagicMock()
    return service
```

## üìù Gu√≠a de Estilo para Pruebas

### Nomenclatura

Seguimos convenciones est√°ndar de Python y pytest:

```python
# Archivos: test_<modulo>.py
test_audio_recorder.py

# Clases: Test<Componente>
class TestAudioRecorder:

# Funciones: test_<accion>_<resultado_esperado>
def test_stop_clears_frames():
def test_process_empty_audio_returns_empty():
```

### Estructura AAA (Arrange-Act-Assert)

Cada prueba debe tener tres secciones claramente identificables:

```python
def test_ejemplo() -> None:
    """Descripci√≥n del caso de prueba."""
    # ARRANGE: Preparar el escenario
    service = MiServicio()
    datos = crear_datos_prueba()

    # ACT: Ejecutar la acci√≥n bajo prueba
    resultado = service.procesar(datos)

    # ASSERT: Verificar el resultado
    assert resultado.exitoso is True
    assert resultado.valor == esperado
```

### Docstrings de pruebas

Los docstrings deben explicar el **por qu√©**, no solo el **qu√©**:

```python
def test_stop_raises_when_not_recording() -> None:
    """Verifica que stop() falle sin grabaci√≥n activa.

    Caso de prueba
    --------------
    Llamar stop() sin haber llamado start() previamente.

    Motivaci√≥n
    ----------
    Un stop() sin start() indica un error de programaci√≥n.
    Preferimos fallar expl√≠citamente a retornar datos incorrectos
    (principio de fail-fast).

    Raises:
        AssertionError: Si no se lanza RecordingError.
    """
```

## üêõ Debugging de Pruebas

### Opciones √∫tiles de pytest

```bash
# Mostrar print() y logging
pytest tests/ -v -s

# Detenerse en el primer fallo
pytest tests/ -x

# Re-ejecutar solo las que fallaron
pytest tests/ --lf

# Entrar al debugger en fallos
pytest tests/ --pdb

# Ejecutar las m√°s lentas primero (√∫til para identificar cuellos de botella)
pytest tests/ --durations=10
```

### Investigar fallos

1. **Lee el mensaje de error completo** - pytest da contexto detallado.
2. **Revisa el diff** - En assertions, muestra qu√© esperabas vs qu√© obtuviste.
3. **Usa -s** - Si tienes prints de debug, -s los muestra.
4. **A√≠sla la prueba** - Corre solo esa prueba con `::nombre_funcion`.

## üìä M√©tricas de Calidad

### Cobertura objetivo

Apuntamos a **‚â•80% de cobertura de l√≠nea** como baseline. Sin embargo,
cobertura alta no garantiza calidad - una prueba puede ejecutar c√≥digo
sin verificar su comportamiento.

**M√°s importante que el n√∫mero:**

- Cubrir los caminos cr√≠ticos (happy paths)
- Cubrir los edge cases conocidos
- Tener al menos un test de regresi√≥n por bug arreglado

### Velocidad de ejecuci√≥n

Las pruebas unitarias deben ser r√°pidas. Si una prueba tarda m√°s de 1 segundo,
considera:

- ¬øEst√° cargando recursos pesados que podr√≠an mockearse?
- ¬øEst√° haciendo I/O que podr√≠a evitarse?
- ¬øDeber√≠a ser una prueba de integraci√≥n?

## ü§ù Contribuci√≥n

### Checklist antes de merge

- [ ] Escrib√≠ pruebas para el c√≥digo nuevo
- [ ] Todas las pruebas pasan (`pytest tests/ -v`)
- [ ] La cobertura no baj√≥ (`pytest --cov --cov-fail-under=80`)
- [ ] Los docstrings explican el prop√≥sito de cada prueba
- [ ] Segu√≠ el patr√≥n AAA y las convenciones de nomenclatura

### Recursos adicionales

- [pytest documentation](https://docs.pytest.org/)
- [Python Testing with pytest](https://pragprog.com/titles/bopytest2/) - Brian Okken
- [xUnit Test Patterns](http://xunitpatterns.com/) - Gerard Meszaros
